version: "3.9"

services:
  postgres:
    container_name: postgres_dedicated_container
    image: postgres:latest
    hostname: ${DB_HOST}
    environment:
      - POSTGRES_DB=${DB_NAME}
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASS}
      - PGDATA=/data/postgres
    volumes:
       - dedicated_postgres:/data/dedicated_postgres
    ports:
      - "5432:5432"
    networks:
      - job_seeker_dev_network

  web:
    build:
      context: .
      dockerfile: ${DOCKER_FILE}
    env_file:
      - .setting_envs/test/.env
      - .setting_envs/local/.django
      - .setting_envs/local/.email
      - .setting_envs/local/.postgres
    expose:
      - ${DJANGO_PORT}
    ports:
      - ${DJANGO_PORT}:${DJANGO_PORT}
    command: sh -c "export DJANGO_SETTINGS_MODULE=${DJANGO_SETTINGS_MODULE} &&
                    export DJANGO_PORT=${DJANGO_PORT} &&
                    python3 entrypoint.py"
    depends_on:
      - postgres
      - rabbitmq
      - redis
      - elastic
    networks:
      - job_seeker_dev_network
    volumes:
      - .:/home/code

  redis:
    image: redis:latest
    ports:
      - '6379:6379'
    networks:
      - job_seeker_dev_network

  rabbitmq:
    image: rabbitmq:3.8-management-alpine
    hostname: ${RABBITMQ_HOST}
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=username
      - RABBITMQ_DEFAULT_PASS=password
    networks:
      - job_seeker_dev_network
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq

  worker:
    build:
      context: .
      dockerfile: ${DOCKER_FILE}
    environment:
      - DJANGO_PORT=${DJANGO_PORT}
      - DJANGO_SETTINGS_MODULE=${DJANGO_SETTINGS_MODULE}
      - DJANGO_REQUIREMENT_FILE=${DJANGO_REQUIREMENT_FILE}
    command: celery -A config.celery worker -B --loglevel=info
    env_file:
      - .setting_envs/local/.django
      - .setting_envs/local/.email
      - .setting_envs/local/.postgres
    depends_on:
      - web
      - redis
      - rabbitmq
    networks:
      - job_seeker_dev_network

  elastic:
    container_name: job_seeker_elastic
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - job_seeker_dev_network
    ports:
      - 9200:9200
    mem_limit: 5g

  kibana:
    container_name: job_seeker_kibana
    image: docker.elastic.co/kibana/kibana:8.11.1
    #restart: always
    environment:
      - ELASTICSEARCH_HOSTS=http://elastic:9200
    networks:
      - job_seeker_dev_network
    ports:
      - 5601:5601
    depends_on:
      - elastic

#  flower:
#    image: job_seeker_dev:$TAG_NAME
#    command: celery -A config flower
#    ports:
#      - "5555:5555"
#    env_file:
#      - .setting_envs/production/.env
#    depends_on:
#      - worker
#      - redis
#    networks:
#      - job_seeker_dev_network

volumes:
  static_volume:
    driver: local
  dedicated_postgres:
  elasticsearch-data:
  rabbitmq_data:

networks:
  job_seeker_dev_network:

#sudo TAG_NAME="latest" docker-compose up
#docker build --build-arg requirement_file=local.txt --no-cache -t job_seeker_dev:1.1.1 -f Dockerfile .
